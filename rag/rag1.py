from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.llms import Tongyi
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv("DASHSCOPE_API_KEY")

# å‡†å¤‡æ–‡æ¡£
docs = [
    "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”¨äºæ•°æ®ç§‘å­¦ã€AIã€Web å¼€å‘",
    "WebRTC æ˜¯å®æ—¶é€šè®¯åè®®ï¼Œç”¨äºéŸ³è§†é¢‘ä¼ è¾“",
    "RAG æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œç»“åˆå‘é‡æ£€ç´¢å’Œå¤§æ¨¡å‹"
]

# åˆ†å‰²
splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
chunks = splitter.split_text("\n".join(docs))

print(f"âœ… åˆ†å‰²å {len(chunks)} ä¸ªchunk")

# åˆ›å»ºå‘é‡åº“
embeddings = DashScopeEmbeddings(model="text-embedding-v3")
vector_store = FAISS.from_texts(chunks, embeddings)

print("âœ… å‘é‡åº“åˆ›å»ºæˆåŠŸ")

# æŸ¥è¯¢
query = "Python ç”¨æ¥åšä»€ä¹ˆï¼Ÿ"
results = vector_store.similarity_search(query, k=2)

print(f"\nğŸ” æŸ¥è¯¢: {query}")
for i, doc in enumerate(results):
    print(f"  {i+1}. {doc.page_content[:50]}...")

# LLM å›ç­”
print("\nâ³ LLM ç”Ÿæˆä¸­...")
llm = Tongyi()
prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜:

ä¿¡æ¯:
{results[0].page_content}

é—®é¢˜: {query}

è¯·ç”¨ç®€æ´çš„ä¸­æ–‡å›ç­”ã€‚"""

answer = llm.invoke(prompt)
print(f"\nâœ… ç­”æ¡ˆ:\n{answer}")